---
title: 네이버 주식토론방 크롤링
date: 2023-11-14 18:19:15 +09:00
categories: [크롤링, selenium, 크롤링, 성공]
tags: [selenium, crawling]
pin: true
---

>대학 자연어처리 과제 준비중!<br/>
>데이터 준비중

# 코드
## version 1
selenium 으로 크롤링을 하기 위해 처음에는 Class name으로 요소를 가저오려 했으나 날짜, 추천, 비추천등 다른 쓸모 없는 요소까지 같은 이름으로 되어있어 다른 방법을 찾아보다 CSS selector를 이용해서 요소를 추출하기로 했다.

<details><summary>코드 version 1</summary>
<div markdown = "1">

```python
import selenium
from selenium import webdriver
import time
import datetime
import pandas as pd
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC

start = time.time()

def max_page():
    chrome_options = webdriver.ChromeOptions()
    chrome_options.add_argument('headless') #코드 완벽할 시 활성화
    #mobile_emulation = {"deviceName": "iPhone 12 Pro"}
    #chrome_options.add_experimental_option("mobileEmulation", mobile_emulation)#모바일 모드 용도
    driver = webdriver.Chrome(options=chrome_options)
    driver.get("https://finance.naver.com/item/board.naver?code=005930")
    driver.find_element(By.CLASS_NAME, 'pgRR').click()
    max_not_clean = driver.find_element(By.CSS_SELECTOR, '#content > div.section.inner_sub > table:nth-child(3) > tbody > tr > td:nth-child(2) > table > tbody > tr > td.on > a').text
    driver.quit()
    max = max_not_clean.replace(",","")
    print("최대값 : ",max)
    return max

page = 2#int(max_page())#최대 99168


all_comment_url = []

date_text = []
title_text = []
body_text = []

for t in range (1, page + 1):
    chrome_options = webdriver.ChromeOptions()
    chrome_options.add_argument('headless')
    driver = webdriver.Chrome(options=chrome_options)
    print("크롤링 페이지 : ",t)
    url = f"https://finance.naver.com/item/board.naver?code=005930&page={t}"
    driver.get(url = url)
    driver.implicitly_wait(10)

    selector = "#content > div.section.inner_sub > table > tbody > tr > td.title > a"
    links = driver.find_elements(By.CSS_SELECTOR, selector)
    for link in links:
        url = link.get_attribute("href")
        all_comment_url.append(url)
    
    time_page_start = time.time()
    for url in all_comment_url:
        print(url)
        driver.get(url=url) 
        driver.implicitly_wait(10)
        date = driver.find_element(By.CLASS_NAME, 'gray03.p9.tah').text
        title_not_clean = driver.find_element(By.CLASS_NAME, 'c.p15').text
        body_not_clean = driver.find_element(By.ID, 'body').text

        body = body_not_clean.replace("\n","")
        title = title_not_clean.replace("#","")
        date_text.append(date)
        title_text.append(title)
        body_text.append(body)
    time_end_page = time.time()
    sec = (time_end_page - time_page_start)
    result = str(datetime.timedelta(seconds=sec)).split(".")
    print(f"페이지{t} : ",result[0])

driver.quit()

df = pd.DataFrame()
df['date'] = date_text
df['title'] = title_text
df['body'] =  body_text

df.to_csv("data/test.txt", index = False, sep='\t')
df.to_excel("data/test.xlsx")
end = time.time()
sec = (end - start)
result = str(datetime.timedelta(seconds=sec)).split(".")
print("전체 페이지 : ",result[0])
```

</div>
</details>
<br/>

## version 2
네이버 주식토론방 크롤링을 하다보면 관리자가 삭제한 글이라는 알람이 뜨며 프로그램을 강제종료 시키기에 exception을 걸어 무시하고 지나갈 수 있게 하였다. 코드에 대한 설명은 추후에 천천히 하나씩 채워나가기로 하겠다.

<details><summary>코드 version 2</summary>
<div markdown = "1">


```python
import selenium
from selenium import webdriver
import time
import datetime
from selenium.common.exceptions import UnexpectedAlertPresentException
import pandas as pd
from selenium.webdriver.common.by import By

start = time.time()

def max_page():
    chrome_options = webdriver.ChromeOptions()
    chrome_options.add_argument('headless') #코드 완벽할 시 활성화
    #mobile_emulation = {"deviceName": "iPhone 12 Pro"}
    #chrome_options.add_experimental_option("mobileEmulation", mobile_emulation)#모바일 모드 용도
    driver = webdriver.Chrome(options=chrome_options)
    driver.get("https://finance.naver.com/item/board.naver?code=005930")
    driver.find_element(By.CLASS_NAME, 'pgRR').click()
    max_not_clean = driver.find_element(By.CSS_SELECTOR, '#content > div.section.inner_sub > table:nth-child(3) > tbody > tr > td:nth-child(2) > table > tbody > tr > td.on > a').text
    driver.quit()
    max = max_not_clean.replace(",","")
    print("최대값 : ",max)
    return max

page = 10#int(max_page())#최대 99168


all_comment_url = []

date_text = []
title_text = []
body_text = []

for t in range (1, page + 1):
    chrome_options = webdriver.ChromeOptions()
    chrome_options.add_argument('headless')
    driver = webdriver.Chrome(options=chrome_options)
    print("크롤링 페이지 : ",t)
    url = f"https://finance.naver.com/item/board.naver?code=005930&page={t}"
    driver.get(url = url)
    driver.implicitly_wait(10)

    selector = "#content > div.section.inner_sub > table > tbody > tr > td.title > a"
    links = driver.find_elements(By.CSS_SELECTOR, selector)
    for link in links:
        url = link.get_attribute("href")
        all_comment_url.append(url)
    
    time_page_start = time.time()
    for url in all_comment_url:
        print(url)
        try:
            driver.get(url=url) 
            driver.implicitly_wait(10)
            date = driver.find_element(By.CLASS_NAME, 'gray03.p9.tah').text
            title_not_clean = driver.find_element(By.CLASS_NAME, 'c.p15').text
            body_not_clean = driver.find_element(By.ID, 'body').text
            body = body_not_clean.replace("\n","")
            title = title_not_clean.replace("#","")
            date_text.append(date)
            title_text.append(title)
            body_text.append(body)           

        except UnexpectedAlertPresentException:#무조건 필요 관리자가 삭제한 글을 불러오지 못할 때에 문제가 아주 크게크게 생김 프로그램이 멈춰버려!
            print("\n관리자가 삭제한 글 임\n")

    time_end_page = time.time()
    sec = (time_end_page - time_page_start)
    result = str(datetime.timedelta(seconds=sec)).split(".")
    print(f"페이지{t} : ",result[0])#시간 표시

driver.quit()

#데이터 프레임 만들어서 저장
df = pd.DataFrame()
df['date'] = date_text
df['title'] = title_text
df['body'] =  body_text

df.to_csv("data/1-100.txt", index = False, sep='\t')
df.to_excel("data/1-100.xlsx")
end = time.time()
sec = (end - start)
result = str(datetime.timedelta(seconds=sec)).split(".")
print("전체 페이지 : ",result[0])

```

</div>
</details>

